[
  {
    "objectID": "wbpip_gd_doc.html",
    "href": "wbpip_gd_doc.html",
    "title": "Group Data Documentation (wbpip)",
    "section": "",
    "text": "This document aims to describe the functions used in wbpip to calculated the poverty and inequality statistics using group data."
  },
  {
    "objectID": "wbpip_gd_doc.html#structure",
    "href": "wbpip_gd_doc.html#structure",
    "title": "Group Data Documentation (wbpip)",
    "section": "Structure",
    "text": "Structure\n\n\n\n\nflowchart RL\n    lz(select_lorenz) --> stats[pip_stats]\n    lq(pip_stats_lq) --> lz\n    lb(pip_stats_lb) --> lz\n\n    \n    form_lq(functional_form_lq) --> lq\n    est_lq(estimate_lq) --> lq\n    fit_lq(fit_lq) --> lq\n    derive_lq(derive_lq) --> lq\n    \n    regres(regres) --> lq\n    regres(regres) --> lb\n    \n    form_lb(functional_form_lb) --> lb\n    est_lb(estimate_lb) --> lb\n    fit_lb(fit_lb) --> lb\n    derive_lb(derive_lb) ---> lb\n\n    check_val(check_curve_validity_lq) --> est_lq\n    comp_dist_lq(compute_dist_stats_lq) --> est_lq\n    comp_pov_lq(compute_pov_stats_lq) --> est_lq\n    \n    check_val_lb(check_curve_validity_lb) --> est_lb\n    derive_lb(derive_lb) ---> check_val_lb\n    ddlk(ddlk) --> check_val_lb\n    \n    comp_dist_lb(compute_dist_stats_lb) --> est_lb\n    derive_lb --> comp_dist_lb\n    value_at_lb --> comp_dist_lb\n    gini_lb --> comp_dist_lb\n    value_at_lb --> gini_lb\n    polarization_lb --> comp_dist_lb\n    derive_lb --> polarization_lb\n    value_at_lb --> polarization_lb\n    quantile_lb --> comp_dist_lb\n    \n    comp_pov_lb(compute_pov_stats_lb) --> est_lb\n    headcount_lb --> comp_pov_lb\n    rtSafe --> headcount_lb\n    funcD --> rtSafe\n    rtNewt --> rtSafe\n    BETAI --> headcount_lb\n    BETAICF --> BETAI\n    GAMMLN --> BETAI\n    pov_gap_lb --> comp_pov_lb\n    pov_severity_lb --> comp_pov_lb\n    \n    value_at_lb --> fit_lb\n    \n    polarization_lq(<b>polarization_lq</b>) --> comp_dist_lq\n    gini_lq(<b>gini_lq</b>) --> comp_dist_lq\n    value_at_lq --> polarization_lq\n    value_at_lq(value_at_lq) --> comp_dist_lq\n    mld_lq(<b>mld_lq</b>) --> comp_dist_lq\n    quantile_lq(<b>quantile_lq</b>) --> comp_dist_lq\n    \n    headcount_lq --> comp_pov_lq\n    pov_gap_lq --> comp_pov_lq\n    pov_severity_lq --> comp_pov_lq\n    watts_lq --> comp_pov_lq\n\n    derive_lq --> comp_dist_lq\n    derive_lq --> mld_lq\n    derive_lq --> polarization_lq\n    value_at_lq --> quantile_lq\n    value_at_lq --> pov_gap_lq\n    value_at_lq --> pov_severity_lq\n    value_at_lq --> fit_lq\n    \n    style derive_lq fill: #50C878\n    style value_at_lq fill: #50C878\n    style check_val fill: #50C878\n    style form_lq fill: #50C878\n    style regres fill: #50C878\n    style gini_lq fill: #FFA500\n    style polarization_lq fill: #FFA500\n    style quantile_lq fill: #FFA500\n    style mld_lq fill: #FFA500\n    style comp_dist_lq fill: #FFF1A2\n    style comp_pov_lq fill: #FFF1A2 \n    style headcount_lq fill: #FFF1A2 \n    style pov_gap_lq fill: #FFF1A2\n    style pov_severity_lq fill: #FFF1A2\n    style watts_lq fill: #FFF1A2"
  },
  {
    "objectID": "wbpip_gd_doc.html#functions",
    "href": "wbpip_gd_doc.html#functions",
    "title": "Group Data Documentation (wbpip)",
    "section": "1 Functions",
    "text": "1 Functions\n\n1.1 pip_stats\nDescription: Compute poverty statistics for grouped data by selecting the best functional fit for the Lorenz curve (either beta or quadratic)\n\n\nShow the code\ngd_compute_pip_stats <- function(welfare,\n                                 povline,\n                                 population,\n                                 requested_mean,\n                                 popshare = NULL,\n                                 default_ppp = 1,\n                                 ppp = NULL,\n                                 p0 = 0.5) {\n\n\n  # Apply Lorenz quadratic fit ----------------------------------------------\n  results_lq <- gd_compute_pip_stats_lq(\n    welfare = welfare,\n    population = population,\n    requested_mean = requested_mean,\n    povline = povline,\n    popshare = popshare,\n    default_ppp = default_ppp,\n    ppp = ppp,\n    p0 = p0\n  )\n\n  # Apply Lorenz beta fit ----------------------------------------------\n  results_lb <- gd_compute_pip_stats_lb(\n    welfare = welfare,\n    population = population,\n    requested_mean = requested_mean,\n    povline = povline,\n    popshare = popshare,\n    default_ppp = default_ppp,\n    ppp = ppp,\n    p0 = p0\n  )\n\n\n  # Apply selection rules ---------------------------------------------------\n  out <- gd_select_lorenz(\n    lq = results_lq,\n    lb = results_lb\n  )\n\n  # Return only subset of variables\n  out <- out[c(\n    \"poverty_line\",\n    \"mean\",\n    \"median\",\n    \"headcount\",\n    \"poverty_gap\",\n    \"poverty_severity\",\n    \"watts\",\n    \"gini\",\n    \"mld\",\n    \"polarization\",\n    \"deciles\"\n  )]\n\n\n  return(out)\n}\n\n\n\n\n\n\n\n\nIssue: Boundary conditions\n\n\n\nAt the moment, this is calculated using \\((\\mu L'(0.001) + 4,\\mu L'(0.98) - 4)\\) (Note: Not sure what is the reason of adding and subtracting 4).\n\n\n\n\n1.2 select_lorenz\nDescription: Select best Lorenz fit and adjust the returned statistics if needed.\n\n\nShow the code\ngd_select_lorenz <- function(lq, lb) {\n\n  # Set default value\n  datamean <- lq[[\"mean\"]]\n  is_valid <- lq[[\"is_valid\"]] | lb[[\"is_valid\"]]\n  is_normal <- lq[[\"is_normal\"]] | lb[[\"is_normal\"]]\n\n  # Selection of Lorenz fit for poverty statistics\n  use_lq_for_pov <- use_lq_for_poverty(\n    lq = lq,\n    lb = lb\n  )\n\n  # Selection of Lorenz fit for distributional statistics\n  use_lq_for_dist <- use_lq_for_distributional(\n    lq = lq,\n    lb = lb\n  )\n\n  # Retrieve distributional statistics\n  dist <- retrieve_distributional(\n    lq = lq,\n    lb = lb,\n    is_valid = is_valid,\n    use_lq_for_dist = use_lq_for_dist\n  )\n\n  # Retrieve poverty statistics\n  pov <- retrieve_poverty(\n    lq = lq,\n    lb = lb,\n    is_normal = is_normal,\n    use_lq_for_pov = use_lq_for_pov\n  )\n\n  return(list(\n    mean             = datamean,\n    poverty_line     = pov[[\"poverty_line\"]],\n    z_min            = dist[[\"z_min\"]],\n    z_max            = dist[[\"z_max\"]],\n    # ppp            = lq[[\"ppp\"]],\n    gini             = dist[[\"gini\"]],\n    median           = dist[[\"median\"]],\n    # rmed           = rmed,\n    rmhalf           = dist[[\"rmhalf\"]],\n    polarization     = dist[[\"polarization\"]],\n    ris              = dist[[\"ris\"]],\n    mld              = dist[[\"mld\"]],\n    dcm              = lq[[\"dcm\"]],\n    deciles          = dist[[\"deciles\"]],\n    headcount        = pov[[\"headcount\"]],\n    poverty_gap      = pov[[\"poverty_gap\"]],\n    poverty_severity = pov[[\"poverty_severity\"]],\n    eh               = pov[[\"eh\"]],\n    epg              = pov[[\"epg\"]],\n    ep               = pov[[\"ep\"]],\n    gh               = pov[[\"gh\"]],\n    gpg              = pov[[\"gpg\"]],\n    gp               = pov[[\"gp\"]],\n    watts            = pov[[\"watts\"]],\n    sse              = dist[[\"sse\"]]\n  ))\n}\n\n\n\n\n1.3 pip_stats_lq\nDescription: Compute poverty statistics for grouped data using the quadratic functional form of the Lorenz qurve.\n\n\nShow the code\ngd_compute_pip_stats_lq <- function(welfare,\n                                    povline,\n                                    population,\n                                    requested_mean,\n                                    popshare = NULL,\n                                    default_ppp,\n                                    ppp = NULL,\n                                    p0 = 0.5) {\n\n  # Adjust mean if different PPP value is provided\n  if (!is.null(ppp)) {\n    requested_mean <- requested_mean * default_ppp / ppp\n  } else {\n    ppp <- default_ppp\n  }\n  # STEP 1: Prep data to fit functional form\n  prepped_data <- create_functional_form_lq(\n    welfare = welfare,\n    population = population\n  )\n\n  # STEP 2: Estimate regression coefficients using LQ parameterization\n  reg_results <- regres(prepped_data, is_lq = TRUE)\n  reg_coef <- reg_results$coef\n\n  A <- reg_coef[1]\n  B <- reg_coef[2]\n  C <- reg_coef[3]\n\n  # Step 2.1: pre-calculate key values\n  kv <- gd_lq_key_values(A, B, C)\n\n  # OPTIONAL: Only when popshare is supplied\n  # return poverty line if share of population living in poverty is supplied\n  # intead of a poverty line\n  if (!is.null(popshare)) {\n    povline <- derive_lq(popshare,\n                         A, B, C,\n                         key_values = kv) * requested_mean\n  }\n\n  # Boundary conditions (Why 4?)\n  z_min <- requested_mean * derive_lq(0.001,\n                                      A, B, C,\n                                      key_values = kv) + 4\n  z_max <- requested_mean * derive_lq(0.980,\n                                      A, B, C,\n                                      key_values = kv) - 4\n  z_min <- if (z_min < 0) 0L else z_min\n\n  results1 <- list(requested_mean, povline, z_min, z_max, ppp)\n  names(results1) <- list(\"mean\", \"poverty_line\", \"z_min\", \"z_max\", \"ppp\")\n\n  # STEP 3: Estimate poverty measures based on identified parameters\n  results2 <- gd_estimate_lq(requested_mean, povline, p0,\n                             A, B, C, key_values = kv)\n\n  # STEP 4: Compute measure of regression fit\n  results_fit <- gd_compute_fit_lq(welfare,\n                                   population,\n                                   results2$headcount,\n                                   A, B, C,\n                                   key_values = kv)\n\n  res <- c(results1,\n           results2,\n           results_fit,\n           reg_results)\n\n  return(res)\n}\n\n\n\n\n1.4 functional_form_lq\nDescription: Prepares data for regression of \\(y(1-y)\\) on \\((x^2-y)\\), \\(y(x-1)\\) and \\((x-y)\\).\n\n\nShow the code\ncreate_functional_form_lq <- function(welfare,\n                                      population) {\n  # CHECK inputs\n  # assertthat::assert_that(is.numeric(population))\n  # assertthat::assert_that(is.numeric(welfare))\n  # assertthat::assert_that(length(population) == length(welfare))\n  # assertthat::assert_that(length(population) > 1)\n\n  # Remove last observation (the functional form for the Lorenz curve already forces\n  # it to pass through the point (1, 1)\n  nobs <- length(population) - 1\n  population <- population[1:nobs]\n  welfare <- welfare[1:nobs]\n\n  # L(1-L)\n  y <- welfare * (1 - welfare)\n  # (P^2-L)\n  x1 <- population^2 - welfare\n  # L(P-1)\n  x2 <- welfare * (population - 1)\n  # P-L\n  x3 <- population - welfare\n\n  return(list(y = y, X = cbind(x1, x2, x3)))\n\n}\n\n\nNote: The last observation of (x,y), which by construction has the value (1, 1), is excluded since the functional form for the Lorenz curve already forces it to pass through the point (1, 1).\nReferences: [1]\nRelevant equations:\nThe general Quadratic Lorenz curve form is:\n\\[ax^2 + bxy + cy^2 + dx + ey + f = 0 \\tag{1}\\]\nwhere \\(y\\) is the vector of cumulative proportion of consumption/income (L) and \\(x\\) is the cumulative proportions of population (P). Using the conditions \\(f=0\\) and \\(e = -(a+b+d+1)\\) the previous equation is rewritten in a linear form as follows (Equation 15 in Villasenor et al, 1989):\n\\[y(1-y) = a(x^2-y) + by(x-1) + d(x-y) \\tag{2}\\]\nThis function prepares data to estimate \\(a\\), \\(b\\), and \\(d\\) (Note: \\(d\\) is named \\(C\\) in wbpip).\n\n\n1.5 value_at_lq\nDescription: Solves for the Quadratic Lorenz curves.\n\n\nShow the code\nvalue_at_lq <- function(x, A, B, C, key_values) {\n\n  # Check for NA, Inf and negative values in x\n  check_NA_Inf_values(x)\n  check_neg_values(x)\n\n  # Calculations\n  # e <- -(A + B + C + 1)\n  # m <- (B^2) - (4 * A)\n  # n <- (2 * B * e) - (4 * C)\n  temp <- (key_values$m * x^2) + (key_values$n * x) + (key_values$e^2)\n  temp[temp < 0] <- 0\n\n  # Solving the equation of the Lorenz curve\n  estle <- -0.5 * ((B * x) + key_values$e + sqrt(temp))\n\n  return(estle)\n}\n\n\nReferences: [1]\nRelevant equations:\nThis function calculates the value at the Quadratic Lorenz Curve. Solving Equation 1 for \\(y\\), and assuming \\(f=0\\) and \\(e = -(a+b+d+1)\\) the density function that better fits income distributions will be (Equation 6b in Villasenor et al, 1989):\n\\[ y= \\Bigl\\{-(bx+e) - (\\alpha x^2 + \\beta x + e^2)^\\frac{1}{2}\\Bigl\\}/2 \\tag{3}\\]\nwhere \\(\\alpha = b^2 -4a\\) and \\(\\beta = 2be - 4d\\).\n\n\n1.6 derive_lq\nDescription: returns the first derivative of the quadratic Lorenz curves with \\(c = 1\\).\n\n\nShow the code\nderive_lq <- function(x, A, B, C, key_values) {\n\n  if (is.null(key_values)) {\n    key_values <- gd_lq_key_values(A, B, C)\n    # e          <- key_values$e\n    # m          <- key_values$m\n    # n          <- key_values$n\n  }\n\n  if (anyNA(x) == TRUE) {\n    cli::cli_abort(\"`x' must be a numeric or integer vector\")\n  }\n  # note:\n  #   alpha --> m\n  #   beta  --> n\n\n  # e <- -(A + B + C + 1)\n  # m <- (B^2) - (4 * A)\n  # n <- (2 * B * e) - (4 * C) # C is called D in original paper, but C in Datt paper\n  tmp <- (key_values$m * x^2) + (key_values$n * x) + (key_values$e^2)\n  tmp[(!is.na(tmp) & tmp < 0)] <- 0 # If tmp == 0, val = Inf.\n\n  # Formula for first derivative of GQ Lorenz Curve\n  val <- -(B / 2) - ((2 * key_values$m * x + key_values$n) / (4 * sqrt(tmp)))\n\n  return(val)\n}\n\n\nReferences: [1]\nRelevant equations:\nThis function computes the first derivative of Equation 3:\n\\[-(b / 2) - (\\beta + 2 \\alpha x) / (4\\sqrt(\\alpha x^2 + \\beta x + e^2) \\tag{4}\\]\n\n\n1.7 estimate_lq\nDescription: Estimates poverty and inequality stats from Quadratic Lorenz fit\n\n\nShow the code\ngd_estimate_lq <- function(mean, povline, p0, A, B, C, key_values) {\n\n  if (is.null(key_values)) {\n    key_values <- gd_lq_key_values(A, B, C)\n  }\n  e  <- key_values$e\n  m  <- key_values$m\n  n  <- key_values$n\n  r  <- key_values$r\n  s1 <- key_values$s1\n  s2 <- key_values$s2\n\n  validity <- check_curve_validity_lq(A, B, C, key_values = key_values)\n                                      #e, m, n, r^2)\n  if (validity$is_valid == FALSE & validity$is_normal == FALSE) {\n    return(empty_gd_compute_pip_stats_response)\n  }\n\n  # Compute distributional measures -----------------------------------------\n  dist_stats <- gd_compute_dist_stats_lq(mean, p0, A, B, C, key_values = key_values)\n\n  # Compute poverty stats ---------------------------------------------------\n  pov_stats  <- gd_compute_poverty_stats_lq(mean, povline, A, B, C, key_values = key_values)\n\n  out <- list(\n    gini = dist_stats$gini,\n    median = dist_stats$median,\n    rmhalf = dist_stats$rmhalf,\n    polarization = dist_stats$polarization,\n    ris = dist_stats$ris,\n    mld = dist_stats$mld,\n    dcm = dist_stats$dcm,\n    deciles = dist_stats$deciles,\n    headcount = pov_stats$headcount,\n    poverty_gap = pov_stats$pg,\n    poverty_severity = pov_stats$p2,\n    eh = pov_stats$eh,\n    epg = pov_stats$epg,\n    ep = pov_stats$ep,\n    gh = pov_stats$gh,\n    gpg = pov_stats$gpg,\n    gp = pov_stats$gp,\n    watts = pov_stats$watts,\n    dl = pov_stats$dl,\n    ddl = pov_stats$ddl,\n    is_normal = validity$is_normal,\n    is_valid = validity$is_valid\n  )\n\n  return(out)\n}\n\n\n\n\n1.8 check_curve_validity_lq\nDescription: Check validity of Lorenz Quadratic fit\n\n\nShow the code\ncheck_curve_validity_lq <- function(A, B, C, key_values) {\n  is_normal <- FALSE\n  is_valid <- FALSE\n  r <- (key_values$r)^2 # formerly, the input to the func was r^2\n\n  # r needs to be > 0 because need to extract sq root\n  if (r < 0) { # now that r is squared, this will never be TRUE\n    return(list( # but r^2 was used as input before `key_values` so\n      is_normal = is_normal, # this was already never executed\n      is_valid = is_valid\n    ))\n  }\n\n  if (key_values$e > 0 || C < 0) {\n    return(list(\n      is_normal = is_normal,\n      is_valid = is_valid\n    ))\n  }\n\n  # Failure conditions for checking theoretically valid Lorenz curve\n  # Found in section 4 of Datt computational tools paper\n  cn1 <- key_values$n^2\n  cn3 <- cn1 / (4 * key_values$e^2)\n\n  if (!((key_values$m < 0) |\n    ((key_values$m > 0) & (key_values$m < cn3) & (key_values$n >= 0)) |\n    ((key_values$m > 0) & (key_values$m < -key_values$n / 2) & (key_values$m < cn3)))) {\n    return(list(\n      is_normal = is_normal,\n      is_valid = is_valid\n    ))\n  }\n\n  is_normal <- TRUE\n  is_valid <- (A + C) >= 0.9\n\n  return(list(\n    is_normal = is_normal,\n    is_valid  = is_valid\n  ))\n}\n\n\nReferences: [1], [2], [3]\nRelevant equations:\nThe function tests for specific assumptions for the Lorenz Quadratic and relies on the formulas from Table 2 in Datt, G (1998) [3]. The nomenclature for some of these formulas differ from Villasenor et al (1989), so this is how they match:\n\\(m = \\alpha = b^2 -4a\\)\n\\(n = \\beta = 2be -4c\\) (\\(c=d\\) for Villasenor et al, 1989)\n\\(r = K*2\\alpha = (n^2 - 4me^2)^\\frac{1}{2}\\)\n\n\n\n\n\n\nIssue: Rename \\(r\\)\n\n\n\nAt the moment, \\(r\\) refers to \\((n^2 - 4me^2)\\) in wbpip. This is already fixed on commit 47852c in branch fix_key_values by Zander (Waiting for merge). We should maybe rename this within this function.\n\n\nThe conditions this function tests are presented in Section 4 of Datt (1998):\nNormality and Validity\n\n\\((n^2 - 4me^2)>0\\) so the square root in \\(r\\) to be positive. (Normality and validity)\n\\(e<0\\) or \\(c>0\\) so \\(L(0,y) = 0\\) and \\(L'(0^{+},y) \\geq 0\\) (Normality and validity)\n\\(a+d \\geq 0.9\\) so \\(L(1,y) = 1\\) (Validity)\n\n\n\n\n\n\n\nIssue: The inequality for \\(a+d\\)\n\n\n\nAt the moment, most test are design for the old validation \\(a+d \\leq 1\\). However, the Corrigendum of the original paper [2] indicates we should use \\(a+d \\geq 1\\)\n\n\nAnd so \\(L''(x,y) \\geq 0\\) for \\(x\\) within \\((0,1)\\):\n\n\\(m < 0\\) (condition on Villasenor et al., 1989)\nif \\(m > 0\\) then \\(m < n^2/4 e^2\\) and \\(n \\leq 0\\) (last condition from Datt,1998)\nif \\(m > 0\\) then \\(m < n^2/4 e^2\\) and \\(m < -n/2\\) (last condition from Datt,1998)\n\n\\(L''(x,y)\\) can be calculated using Equation 4:\n\\[ \\frac{\\beta^2 -4\\alpha e^2}{8(\\alpha x^2 + \\beta x + e^2)^\\frac{3}{2}} = \\frac{n^2 - 4me^2}{8(mx^2 +nx +e^2)^\\frac{3}{2}}=\\frac{r^2}{8(mx^2 +nx +e^2)^\\frac{3}{2}} \\]\n\n\n1.9 compute_dist_stats_lq\nDescription: Computes distributional stats from Lorenz Quadratic fit\n\n\nShow the code\ngd_compute_dist_stats_lq <- function(mean, p0, A, B, C, key_values = key_values) {\n\n  gini    <- gd_compute_gini_lq(A, B, C,\n                                key_values = key_values)\n  median  <- mean * derive_lq(0.5, A, B, C,\n                              key_values = key_values)\n  rmhalf  <- value_at_lq(p0, A, B, C,\n                         key_values = key_values) * mean / p0 # What is this??\n  dcm     <- (1 - gini) * mean\n  pol     <- gd_compute_polarization_lq(mean, p0, dcm, A, B, C,\n                                        key_values = key_values)\n  ris     <- value_at_lq(0.5, A, B, C,\n                         key_values = key_values)\n  mld     <- gd_compute_mld_lq(A, B, C,\n                               key_values = key_values)\n  deciles <- gd_compute_quantile_lq(A, B, C,\n                                    key_values = key_values)\n\n  return(list(\n    gini         = gini,\n    median       = median,\n    rmhalf       = rmhalf,\n    dcm          = dcm,\n    polarization = pol,\n    ris          = ris,\n    mld          = mld,\n    deciles      = deciles\n  ))\n}\n\n\n\n\n\n\n\n\nCheck:\n\n\n\nWhat is the difference with gd_estimate_dist_stats_lq?\n\n\n\n\n1.10 quantile_lq\nDescription: Compute quantiles from Lorenz Quandratic fit\n\n\nShow the code\nold_gd_compute_quantile_lq <- function(A, B, C, n_quantile = 10) {\n  vec <- vector(mode = \"numeric\", length = n_quantile)\n  x1 <- 1 / n_quantile\n  q <- 0L\n  lastq <- 0L\n  for (i in seq_len(n_quantile - 1)) {\n    q <- value_at_lq(x1, A, B, C)\n    v <- q - lastq\n    vec[i] <- v\n    lastq <- q\n    x1 <- x1 + 1 / n_quantile\n  }\n  vec[n_quantile] <- 1 - lastq\n\n  return(vec)\n}\n\n\nNote: This function calculates the quantiles for a Lorenz Quadratic with specific values for \\(a\\), \\(b\\) and \\(d\\).\n\n\n\n\n\n\nIssues:\n\n\n\nThe description of this function indicates that it calculates the quantiles (deciles) for the density for some specific values of \\(a\\), \\(b\\) and \\(d\\), but it calculates instead the “share” or the value between the deciles. If I understand correctly, the density is the lorenz curve and the share will refer to the deciles of the welfare vector.\nRegarding the last decile, they manually calculated it by subtracting 1 to the second-to-last decile:\nvec[n_quantile] <- 1 - value_at_lq(x[n_quantile-1], A, B, C) where n_quantile = 10\nHowever, my hypothesis is that this is related to Issue: The inequality for \\(a+d\\) above. If \\(A+C \\geq 1\\) then value_at_lq(1, A, B, C) = 1. We can see the case in this Desmos graph.\n\n\nMy version of the code:\n\n\nShow the code\ngd_compute_quantile_lq <- function(A, B, C, n_quantile = 10) {\n\n  x   <- seq(from = 1/n_quantile, to = 1, by = 1/n_quantile)\n\n  vec <- diff(c(0,value_at_lq(x, A, B, C)))\n\n  vec[n_quantile] <- 1- value_at_lq(x[n_quantile-1], A, B, C) # Is this correct?\n\n  return(vec)\n}\n\n\n\n\n1.11 mld_lq\nDescription: Computes Mean Log Deviation from Lorenz Quadratic fit\n\n\nShow the code\nold_gd_compute_mld_lq <- function(A, B, C) {\n  x1 <- derive_lq(0.0005, A, B, C)\n  gap <- 0L\n  mld <- 0L\n  if (x1 == 0) {\n    gap <- 0.0005\n  } else {\n    mld <- suppressWarnings(log(x1) * 0.001)\n  }\n  x1 <- derive_lq(0, A, B, C)\n  for (xstep in seq(0, 0.998, 0.001)) {\n    x2 <- derive_lq(xstep + 0.001, A, B, C)\n    if ((x1 <= 0) || (x2 <= 0)) {\n      gap <- gap + 0.001\n      if (gap > 0.5) {\n        return(-1)\n      }\n    } else {\n      gap <- 0L\n      mld <- mld + (log(x1) + log(x2)) * 0.0005\n    }\n    x1 <- x2\n  }\n  return(-mld)\n}\n\n\nReferences: None\nNote: In this function, they do not describe how the function is calculated. The following is my hypothesis of what they were trying to accomplish:\nRelevant equations:\nThe mean log deviation:\n\\[-\\frac{1}{N} \\sum_{i=1}^N ln(\\frac{y_i}{\\mu})=-\\frac{1}{N} \\sum_{i=1}^N ln(\\frac{y_i}{\\frac{1}{N}\\sum_{i=1}^N y_i}) \\]\nUsing the derivation from Rohde (2008) (Equation 15.20), we know that:\n\\[L'(\\pi) = \\frac{N y_k}{\\sum_{k=1}^N y_k}\\]\nwhere \\(y_k\\) is the income accruing to the \\(k_{th}\\) individual if ordered such that \\(y_1<y_2<...<y_k\\) and \\(\\pi= \\frac{k}{j}\\). Then the mean log deviation can be rewritten as (Equation 15.21):\n\\[-\\int_0^1 ln(L'(\\pi))d\\pi= \\lim_{n \\rightarrow \\infty} -\\sum_{i=1}^{N}\\frac{1}{N}ln(\\frac{N y_k}{\\sum_{k=1}^N y_k})\\]\n\n\n\n\n\n\nIssue:\n\n\n\nMy hypothesis is that they used the last formula to calculate the Mean Log Deviation. I am still unsure why they used some rules at the lower end, more specifically why they return \\(1\\) if for the left tail of \\(y\\) we encounter negative values.\n\n\nMy version of the code:\n\n\nShow the code\ngd_compute_mld_lq <- function(A, B, C) {\n  x1 <- derive_lq(0.0005, A, B, C) \n  mld <- 0L\n  if (x1 != 0) { \n    mld <- suppressWarnings(log(x1) * 0.001) # Needed to match test\n  }\n\n  xstep <- seq(0, 0.999, 0.001)\n  x <- derive_lq(xstep, A, B, C)\n\n  if (any(x[1:33]<=0)){ # To account for negative values \n    return(-1)\n  }else{\n    mld <- mld + fsum( (log(x[1:999])+log(x[2:1000])) *0.0005) \n    return(-mld)\n  }\n}\n\n\n\n\n1.12 gini_lq\nDescription: Compute Gini index from Lorenz Quadratic fit.\n\n\nShow the code\ngd_compute_gini_lq <- function(A, B, C, key_values) {\n\n  # For the GQ Lorenz curve, the Gini formula are valid under the condition A+C>=1\n  # P.isValid <- (A + C) >= 0.9\n  # P.isNormal <- TRUE\n\n  e1 <- abs(A + C - 1)\n  e2 <- 1 + (B / 2) + key_values$e\n\n  tmp1 <- key_values$n * (B + 2) / (4 * key_values$m)\n  tmp2 <- (key_values$r^2) / (8 * key_values$m)\n  tmp3 <- (2 * key_values$m) + key_values$n\n\n  if (key_values$m > 0) {\n    # tmpnum <- tmp3 + 2 * sqrt(m) * abs(e)\n    # tmpden <- n - 2 * abs(e) * sqrt(m)\n\n    # Formula from Datt paper\n    # CHECK that code matches formulas in paper\n    gini <- e2 + (tmp3 / (4 * key_values$m)) * e1 - (key_values$n * abs(key_values$e) / (4 * key_values$m)) - ((key_values$r^2) / (8 * sqrt(key_values$m)^3)) *\n      log(abs(((tmp3 + (2 * sqrt(key_values$m) * e1))) / (key_values$n + (2 * sqrt(key_values$m) * abs(key_values$e)))))\n    # P.gi <- (e/2) - tmp1 - (tmp2 * log(abs(tmpnum/tmpden)) / sqrt(m))\n  } else {\n    tmp4 <- ((2 * key_values$m) + key_values$n) / key_values$r\n    tmp4 <- if (tmp4 < -1) -1 else tmp4\n    tmp4 <- if (tmp4 > 1) 1 else tmp4\n\n    # Formula does not match with paper\n    gini <- e2 +\n      (tmp3 / (4 * key_values$m)) *\n      e1 - (key_values$n * abs(key_values$e) / (4 * key_values$m)) +\n      (tmp2 * (asin(tmp4) - asin(key_values$n / key_values$r)) / sqrt(-key_values$m))\n    # P.gi <- (e/2) - tmp1 + ((tmp2 * (asin(tmp4) - asin(n/r))) / sqrt(-m))\n  }\n\n  return(gini)\n}\n\n\nReferences: [3]\nRelevant equations:\n\nif \\(m<0\\):\n\n\\[ \\frac{e}{2} - \\frac{n (b+2)}{4m} + \\frac{r^2}{8m\\sqrt{-m}}\\left[ \\sin^{-1} \\frac{2 + n}{r} - \\sin^{-1} \\frac{2 + n}{r} \\right]\\]\n\nif \\(m>0\\):\n\n\\[  \\frac{e}{2} - \\frac{n (b+2)}{4m} - \\frac{r^2}{8m\\sqrt{m}} \\ln \\left[\\left|{\\frac{2m+n+2\\sqrt{m} (a+c-1)}{n-2e\\sqrt{m}}}\\right| \\right] \\] ::: {#imp-gini-gd-issue .callout-important} #### Issue:\nThe formula does not match the Datt paper Gini formula as mentioned previously by Tony.\n:::\n\n\n1.13 polarization_lq\nDescription: Computes polarization index from parametric Lorenz fit\n\n\nShow the code\ngd_compute_polarization_lq <- function(mean,\n                                       p0,\n                                       dcm,\n                                       A, B, C,\n                                       key_values) {\n  pol <- 2 - (1 / p0) +\n    (dcm - (2 * value_at_lq(p0, A, B, C, key_values) * mean)) /\n      (p0 * mean * derive_lq(p0, A, B, C, key_values))\n\n  return(pol)\n}\n\n\nReferences: None\nRelevant equations: None\nQuestions: What is p0?\n\n\n1.14 pip_stats_lb\nDescription: Compute poverty statistics for grouped data using the beta functional form of the Lorenz qurve.\n\n\nShow the code\ngd_compute_pip_stats_lb <- function(welfare,\n                                    povline,\n                                    population,\n                                    requested_mean,\n                                    popshare = NULL,\n                                    default_ppp,\n                                    ppp = NULL,\n                                    p0 = 0.5) {\n\n  # Adjust mean if different PPP value is provided\n  if (!is.null(ppp)) {\n    requested_mean <- requested_mean * default_ppp / ppp\n  } else {\n    ppp <- default_ppp\n  }\n  # STEP 1: Prep data to fit functional form\n  prepped_data <- create_functional_form_lb(\n    welfare = welfare,\n    population = population\n  )\n\n  # STEP 2: Estimate regression coefficients using LB parameterization\n  reg_results <- regres(prepped_data, is_lq = FALSE)\n  reg_coef <- reg_results$coef\n\n  A <- reg_coef[1]\n  B <- reg_coef[2]\n  C <- reg_coef[3]\n\n  # OPTIONAL: Only when popshare is supplied\n  # return poverty line if share of population living in poverty is supplied\n  # instead of a poverty line\n\n  if (!is.null(popshare)) {\n    povline <- derive_lb(popshare, A, B, C) * requested_mean\n  }\n\n  # Boundary conditions (Why 4?)\n  z_min <- requested_mean * derive_lb(0.001, A, B, C) + 4\n  z_max <- requested_mean * derive_lb(0.980, A, B, C) - 4\n  z_min <- if (z_min < 0) 0L else z_min\n\n  results1 <- list(requested_mean, povline, z_min, z_max, ppp)\n  names(results1) <- list(\"mean\", \"poverty_line\", \"z_min\", \"z_max\", \"ppp\")\n\n  # STEP 3: Estimate poverty measures based on identified parameters\n  results2 <- gd_estimate_lb(requested_mean, povline, p0, A, B, C)\n\n  # STEP 4: Compute measure of regression fit\n  results_fit <- gd_compute_fit_lb(welfare, population, results2$headcount, A, B, C)\n\n  res <- c(results1, results2, results_fit, reg_results)\n\n  return(res)\n}\n\n\n\n\n1.15 functional_form_lb\nDescription: Prepare data for Lorenz beta regression: \\(Log(L(p) - p) = \\log(a) + \\alpha \\log(p) + \\beta \\log(1 - p)\\).\n\n\nShow the code\ncreate_functional_form_lb <- function(welfare, population) {\n  # CHECK inputs\n  # assertthat::assert_that(is.numeric(population))\n  # assertthat::assert_that(is.numeric(welfare))\n  # assertthat::assert_that(length(population) == length(welfare))\n  # assertthat::assert_that(length(population) > 1)\n\n  # Remove last observation (the functional form for the Lorenz curve already forces\n  # it to pass through the point (1, 1)\n  nobs <- length(population) - 1\n  population <- population[1:nobs]\n  welfare <- welfare[1:nobs]\n\n  # y\n  y <- log(population - welfare)\n  # x1\n  x1 <- 1L\n  # x2\n  x2 <- log(population)\n  # x3\n  x3 <- log(1 - population)\n\n  return(list(y = y, X = cbind(x1, x2, x3)))\n\n}\n\n\nReferences: [5], [3]\nNote: The last observation of (p,l), which by construction has the value (1, 1), is excluded since the functional form for the Lorenz curve already forces it to pass through the point (1, 1).\nRelevant equations:\nThe general Beta Lorenz curve (Kakwani, 1980) form is: \\[ L(p) = p - a p^\\alpha (1-p)^\\beta \\tag{5}\\]\nwhere \\(L(p)\\) is the vector of cumulative proportion of consumption/income and \\(p\\) is the cumulative proportions of population. They correspond to \\(y\\) and \\(x\\) in the Quadratic Lorenz form.\nNote that in Datt (1998), the parameters have different letters: \\[ L(p) = p - \\theta p^\\gamma (1-p)^\\delta \\tag{6}\\]\nIn our code, the parameters are addressed respectively as: $$\n\\[\\begin{aligned}\nA = a = \\theta \\\\\n\nB = \\alpha = \\gamma \\\\\n\nC = \\beta = \\delta\n\\end{aligned}\\]\n$$\nThe previous equation is logged and rewritten as follows: $$\n\\[\\begin{aligned}\nL(p) = p - a p^\\alpha (1-p)^\\beta \\\\\n\nL(p) - p = - a p^\\alpha (1-p)^\\beta \\\\\n\np - L(p) = a p^\\alpha (1-p)^\\beta \\\\\n\nLog(p - L(p)) =\n\n\\log(L(p) - p) = \\log(a) + \\alpha \\log(p) + \\beta \\log(1 - p)\n\n\\end{aligned}\\]\n$$ ### value_at_lb Description: Solves for the Beta Lorenz curve.\n\n\nShow the code\nvalue_at_lb <- function(x, A, B, C) {\n\n  # Check for NA, Inf and negative values in x\n  check_NA_Inf_values(x)\n  check_neg_values(x)\n\n  out <- x - (A * (x^B) * ((1 - x)^C))\n\n  return(out)\n}\n\n\nReferences: [5]\nThis function calculates the value at the Beta Lorenz Curve. It solves Equation 5 for \\(L(p)\\).\n\n\n1.16 derive_lb\nDescription: returns the first derivative of the Beta Lorenz curves.\n\n\nShow the code\nderive_lb <- function(x, A, B, C) {\n  val <- vector(\"numeric\", length(x))\n  val[x == 0] <- -Inf\n  val[x == 1] <- Inf\n\n  if (B == 1) {\n      val[x == 0] <- 1 - A\n    }\n    if (B > 1) {\n      val[x == 0] <- 1\n    }\n    if (C == 1) {\n      val[x == 1] <- 1 + A\n    }\n    if (C > 1) {\n      val[x == 1] <- 1\n    } else {\n\n      # Formula for first derivative of GQ Lorenz Curve\n      new_x <- x[!(x %in% c(0,1))]\n      val[!(x %in% c(0,1))] <- 1 - ((A * new_x^B) * ((1 - new_x)^C) * ((B / new_x) -( C / (1 - new_x)) ) )\n    }\n  return(val)\n}\n\n\nReferences: [3]\nRelevant equations:\nAs noted above, in our code, the parameters are addressed respectively as: $$\n\\[\\begin{aligned}\nA = a = \\theta \\\\\n\nB = \\alpha = \\gamma \\\\\n\nC = \\beta = \\delta\n\\end{aligned}\\]\n$$\nAdditionally, \\(p = x\\) and \\(L(p) = y\\). We will use the code notation for practicality.\nThis function computes the first derivative of Equation 5, which is derived as follows:\n\\[\\begin{aligned}\ny &= x - A x^B (1-x)^C \\\\\ny' &= a A (1-x)^{C-1} x^B - AB(1-x)^C x^{B-1} + 1\\\\\n&= 1 - A (1-x)^C x^B \\left[\\frac{C}{1-x} - \\frac{B}{x}\\right]\n\\end{aligned}\\]\n\n\n\n\n\n\nIssues:\n\n\n\nThere are a series of boundary conditions for the first derivative, but I cannot find the reason for those boundary conditions in the literature. The conditions are the following:\n\nat \\(x = 0\\):\n\nif \\(B = 1\\) -> \\(1 - A\\)\nif \\(B > 1\\) -> \\(1\\)\n\nat \\(x = 1\\):\n\nif \\(C = 1\\) -> \\(1 + A\\)\nif \\(C > 1\\) -> \\(1\\)\n\n\nAccording to Kakwani (1980) and the rest of the literature, the only condition for \\(L'(x) = y'\\) is to be \\(>=0\\) at \\(x = 0\\). Now, if we follow the execution of the function, it is true that when \\(x=0\\), \\(\\frac{B}{X} = \\frac{B}{0} = undefined\\),which would cause calculation issues, but the rest of the derivative already sets \\(L'(x) = 1\\), so it is not clear to me why we have to set it to \\(1-A\\) or \\(1\\). The same sort of reasoning applies at \\(x = 1\\), but with the parameter \\(C\\).\n\n\n\n\n1.17 estimate_lb\nDescription: Estimates poverty and inequality stats from the Beta Lorenz fit.\n\n\nShow the code\ngd_estimate_lb <- function(mean, povline, p0, A, B, C) {\n\n  # Compute distributional measures\n  dist_stats <- gd_compute_dist_stats_lb(mean, p0, A, B, C)\n\n  # Compute poverty stats\n  pov_stats <- gd_compute_poverty_stats_lb(mean, povline, A, B, C)\n\n  # Check validity\n  validity <- check_curve_validity_lb(headcount = pov_stats[[\"headcount\"]], A, B, C)\n\n  out <- list(\n    gini = dist_stats$gini,\n    median = dist_stats$median,\n    rmhalf = dist_stats$rmhalf,\n    polarization = dist_stats$polarization,\n    ris = dist_stats$ris,\n    mld = dist_stats$mld,\n    dcm = dist_stats$dcm,\n    deciles = dist_stats$deciles,\n    headcount = pov_stats$headcount,\n    poverty_gap = pov_stats$pg,\n    poverty_severity = pov_stats$p2,\n    eh = pov_stats$eh,\n    epg = pov_stats$epg,\n    ep = pov_stats$ep,\n    gh = pov_stats$gh,\n    gpg = pov_stats$gpg,\n    gp = pov_stats$gp,\n    watts = pov_stats$watts,\n    dl = pov_stats$dl,\n    ddl = pov_stats$ddl,\n    is_normal = validity$is_normal,\n    is_valid = validity$is_valid\n  )\n\n  return(out)\n}\n\n\n\n\n1.18 check_curve_validity_lb\nDescription: Check validity of Lorenz Beta fit:\n\n\nShow the code\ncheck_curve_validity_lb <- function(headcount, A, B, C) {\n  is_valid <- TRUE\n\n  for (w in seq(from = 0.001, to = 0.1, by = 0.05)) {\n    if (derive_lb(w, A, B, C) < 0) {\n      is_valid <- FALSE\n      break\n    }\n  }\n\n  if (is_valid) {\n    for (w in seq(from = 0.001, to = 0.999, by = 0.05)) {\n      if (DDLK(w, A, B, C) < 0) { # What does DDLK stands for?? What does it do?\n        is_valid <- FALSE\n        break\n      }\n    }\n  }\n\n  # WHAT IS THE RATIONAL HERE?\n  is_normal <- if (!is.na(headcount)) {\n    is_normal <- TRUE\n  } else {\n    is_normal <- FALSE\n  }\n\n  return(list(\n    is_valid = is_valid,\n    is_normal = is_normal\n  ))\n}\n\n\nReferences: [1], [3]\nThe function tests for specific assumptions for the Lorenz Beta and relies on the formulas from Table 2 in Datt, G (1998) [3].\n\n\n1.19 DDLK\nDescription\n\n\n1.20 compute_poverty_stats_lb\nDescription\n\n\nShow the code\ngd_compute_poverty_stats_lb <- function(mean,\n                                        povline,\n                                        A,\n                                        B,\n                                        C) {\n  # Compute headcount\n  headcount <- gd_compute_headcount_lb(\n    mean = mean,\n    povline = povline,\n    A = A,\n    B = B,\n    C = C\n  )\n\n  # Poverty gap\n  u <- mean / povline\n  pov_gap <- gd_compute_pov_gap_lb(headcount = headcount,\n                                   A         = A,\n                                   B         = B,\n                                   C         = C,\n                                   u         = u)\n\n  # Poverty severity\n  pov_gap_sq <- gd_compute_pov_severity_lb(\n    headcount = headcount,\n    pov_gap   = pov_gap,\n    A         = A,\n    B         = B,\n    C         = C,\n    u         = u\n  )\n\n  # First derivative of the Lorenz curve\n  dl <- 1 - A * (headcount^B) * ((1 - headcount)^C) * (B / headcount - C / (1 - headcount))\n\n  # Second derivative of the Lorenz curve\n  ddl <- A * (headcount^B) *\n    ((1 - headcount)^C) *\n    ((B * (1 - B) / headcount^2) +\n      (2 * B * C / (headcount * (1 - headcount))) +\n      (C * (1 - C) / ((1 - headcount)^2)))\n\n  # Elasticity of headcount index w.r.t mean\n  eh <- -povline / (mean * headcount * ddl)\n\n  # Elasticity of poverty gap index w.r.t mean\n  epg <- 1 - (headcount / pov_gap)\n\n  # Elasticity of distributionally sensitive FGT poverty measure w.r.t mean\n  ep <- 2 * (1 - pov_gap / pov_gap_sq)\n\n  # PElasticity of headcount index w.r.t gini index\n  gh <- (1 - povline / mean) / (headcount * ddl)\n\n  # Elasticity of poverty gap index w.r.t gini index\n  gpg <- 1 + (((mean / povline) - 1) * headcount / pov_gap)\n\n  # Elasticity of distributionally sensitive FGT poverty measure w.r.t gini index\n  gp <- 2 * (1 + (((mean / povline) - 1) * pov_gap / pov_gap_sq))\n\n  # Watts index\n  watts <- gd_compute_watts_lb(headcount, mean, povline, 0.005, A, B, C)\n\n  return(\n    list(\n      headcount = headcount,\n      pg = pov_gap,\n      p2 = pov_gap_sq,\n      eh = eh,\n      epg = epg,\n      ep = ep,\n      gh = gh,\n      gpg = gpg,\n      gp = gp,\n      watts = watts,\n      dl = dl,\n      ddl = ddl\n    )\n  )\n}\n\n\n\n\n1.21 compute_headcount_lb\nDescription: This function calculates the poverty headcount \\(H\\) using the Lorenz Beta. It also checks whether BETAI evaluates to NA when run with the same parameters.\n\n\nShow the code\ngd_compute_headcount_lb <- function(mean, povline, A, B, C) {\n  # Compute headcount\n  \n  # First, the function uses rtSafe to bracket the root and solve for H:\n  headcount <- rtSafe(0.0001, 0.9999, 1e-4,\n    mean = mean,\n    povline = povline,\n    A = A,\n    B = B,\n    C = C\n  )\n  \n  # Then, it checks headcount invalidity conditions:\n  if (headcount < 0 | is.na(headcount)) {\n    return(NA_real_)\n  }\n  \n  # It also checks whether the BETAI for these parameters is NA, if so it would prevent us from using it in the next calculations. \n  condition1 <- is.na(BETAI(\n    a = 2 * B - 1,\n    b = 2 * C + 1,\n    x = headcount\n  ))\n  \n  condition2 <- is.na(BETAI(\n    a = 2 * B,\n    b = 2 * C,\n    x = headcount\n  ))\n  \n  condition3 <- is.na(BETAI(\n    a = 2 * B + 1,\n    b = 2 * C - 1,\n    x = headcount\n  ))\n  \n  # If any of the conditions is NA, it returns NA altogether.\n  if (condition1 | condition2 | condition3) {\n    return(NA_real_)\n  }\n\n  return(headcount)\n}\n\n\nReferences:\nRelevant equations:\n\n\n1.22 BETAI\nDescription: BETAI calculates the incomplete Beta function using the continuous fraction implementation (BETAICF), and the gamma function (GAMMALN) for convergence.\n\n\nShow the code\nBETAI <- function(a, b, x) {\n  if (!is.na(x)) {\n    bt <- betai <- 0\n\n    if (x == 0 || x == 1) {\n      bt <- 0\n    } else {\n      bt <- exp((a * log(x)) + (b * log(1 - x)))\n    }\n\n    if (x < (a + 1) / (a + b + 2)) {\n      betai <- bt * BETAICF(a, b, x) / a\n    } else if (is.na(GAMMLN(a)) || is.na(GAMMLN(b)) || is.na(GAMMLN(a + b))) {\n      betai <- NA_real_\n    } else {\n      # I think this is wrong, it should be 1 - I_(1-x)(b,a), this is just I_(1-x)(b,a).\n      betai <- exp(GAMMLN(a) + GAMMLN(b) - GAMMLN(a + b)) - (bt * BETAICF(b, a, 1 - x) / b)\n    }\n  } else {\n    betai <- NA_real_\n  }\n\n  return(betai)\n}\n\n\nReferences:[6]\nRelevant equations:\nThe incomplete beta function is defined by \\[I_x(a, b) = \\frac{B_x(a, b)}{B(a, b)} = \\frac{1}{B(a, b)} \\int_0^x t^{a-1}(1-t)^{b-1} \\, dt \\quad (a, b > 0)\\] It has the limiting values: \\[I_0(a, b) = 0 \\quad I_1(a, b) = 1\\] and the symmetry relation: \\[I_x(a, b) = 1 - I_{1-x}(b, a)\\]\nIf \\(a\\) and \\(b\\) are both way above one, then \\(I_0(a, b)\\) rises from near-zero to near-unity sharply at about \\(x = a/(a+b)\\). The continued fraction representation of this function is better suitable than the expansion for numerical evaluation (see equation in the BETAICF documentation below).\nBETAICF converges rapidly for \\(x < (a + 1)/(a + b + 2)\\), but for \\(x < (a + 1)/(a + b + 2)\\) we can use the symmetry relation to obtain a form which will also converge quickly (the symmetric version, \\(1 - I_{1-x}(b, a)\\))\n\n\n\n\n\n\nIssue:\n\n\n\nFollowing the reasoning of [6] and the code provided (written in C), I believe that our current code does not calculate the correct incomplete beta. Here are the step to calculate the Beta correctly:\n\\[\\begin{align*}\nI_x(a, b) &= \\frac{x^a(1 - x)^b}{aB(a, b)} \\left[ \\frac{1}{1 + \\frac{d_1}{1 + \\frac{d_2}{1 + \\cdots}}} \\right] \\\\\n&= \\frac{x^a(1 - x)^b}{a \\color{blue}{B(a, b)}} \\times BETAICF(.)\n\\end{align*}\\] In our code, the second part of this multiplication is calculated using BETAICF function. Now, In order to calculate \\(B(a,b)\\) (blue above) we need to use the relationship between the Beta and the gamma function: \\[B(a,b) = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}\\] However, as explained in GAMMALN, it is faster and more reliable to calculate \\(log\\Gamma(a,b)\\), which is what our GAMMALN function does. Therefore, we need to calculate:\n\\[\\begin{align*}\nI_x(a, b) &= \\frac{x^a(1 - x)^b}{aB(a, b)} \\left[ \\frac{1}{1 + \\frac{d_1}{1 + \\frac{d_2}{1 + \\cdots}}} \\right] \\\\\n&= \\frac{\\color{green}{x^a(1 - x)^b}}{a \\color{blue}{B(a, b)}} \\times BETAICF(.) \\\\\n&= exp(\\color{blue}{GAMMALN(a+b) - GAMMALN(a) - GAMMALN(b)} \\\\\n& \\quad + \\color{green}{a \\cdot log(x) + b \\cdot log(1-x)}) \\times BETAICF(a, b, x) \\cdot 1/a\n\\end{align*}\\]\nHowever, when \\(x > (a + 1) / (a + b + 2)\\), we need to use the symmetry property and calculate instead: \\[\\begin{align*}\n1 - I_{1-x}(b,a) &= 1 - exp(\\color{blue}{GAMMALN(a+b) - GAMMALN(a) - GAMMALN(b)} \\\\\n& \\quad + \\color{green}{a \\cdot log(x) + b \\cdot log(1-x)}) \\times BETAICF(b, a, 1-x) \\cdot 1/b\n\\end{align*}\\]\nTherefore, the correct implementation of the function should be something like:\n\n\nShow the code\nBETAI <- function(a, b, x) {\n  if (!is.na(x)) {\n    bt <- betai <- 0\n\n    if (x == 0 || x == 1) {\n      bt <- 0\n    } else {\n      bt <- exp(GAMMLN(a+b) - GAMMLN(a) - GAMMLN(b) + a*log(x) + b*log(1-x)) # the term bt has already the gammaln() and it is already exp() in this version\n    }\n\n    if (x < (a + 1) / (a + b + 2)) {\n      betai <- bt * BETAICF(a, b, x) / a # here we keep the I_x(a,b)\n    } else if (is.na(GAMMLN(a)) || is.na(GAMMLN(b)) || is.na(GAMMLN(a + b))) {\n      betai <- NA_real_\n    } else {\n      betai <- 1 - bt * BETAICF(b, a, 1 - x) / b #and here we use the inverse 1-I_(1-x)(b,a)\n    }\n  } else {\n    betai <- NA_real_\n  }\n\n  return(betai)\n}\n\n\n\n\n\n\n1.23 BETAICF\nDescription Used by BETAI. This function evaluates continued fraction for incomplete\n\n\nShow the code\nBETAICF <- function(a, b, x) {\n  eps <- 3e-7\n  am <- 1\n  bm <- 1\n  az <- 1\n  qab <- a + b\n  qap <- a + 1\n  qam <- a - 1\n  bz <- c( 1 - (qab * x / qap), rep(1, 99))\n\n  m <- 1:100\n  em <- 1:100\n  tem <- em * 2\n  d <- em * (b - m) * x / ((qam + tem) * (a + tem))\n  d2 <- -(a + em) * (qab + em) * x / ((a + tem) * (qap + tem))\n\n  for (i in seq_len(100)) {\n    ap <- az + (d[i] * am)\n    bp <- bz[i] + (d[i] * bm)\n    app <- ap + (d2[i]  * az)\n    bpp <- bp + (d2[i] * bz[i])\n    aold <- az\n    am <- ap / bpp\n    bm <- bp / bpp\n    az <- app / bpp\n    if ((abs(az - aold)) < (eps * abs(az))) {\n      break\n    }\n  }\n  return(az)\n}\n\n\nReferences: [6]\nRelevant equations: The incomplete beta function in continuous fraction representation is defined as: \\[I_x(a, b) = \\frac{x^a(1 - x)^b}{aB(a, b)} \\color{blue}\\left[ \\frac{1}{1 + \\frac{d_1}{1 + \\frac{d_2}{1 + \\cdots}}} \\right]\\] where \\[d_{2m+1} = -\\frac{(a + m)(a + b + m)x}{(a + 2m)(a + 2m + 1)}\\] and \\[d_{2m} = \\frac{m(b - m)x}{(a + 2m - 1)(a + 2m)}\\] This function calculates the second part, highlighted in blue in the formula above.\n\n\n1.24 GAMMLN\nDescription: GAMMLN calculates the logarithm of the gamma function, \\(log(\\Gamma(.))\\). It is used as part of the BETAI function.\n\n\nShow the code\nGAMMLN <- function(xx) {\n  cof <- c(76.18009173, \n           -86.50532033, \n           24.01409822, \n           -1.231739516, \n           0.120858003e-2, \n           -0.536382e-5)\n  \n  stp <- 2.50662827465\n  fpf <- 5.5\n  x <- xx - 1\n  tmp <- x + fpf\n  \n  if (tmp <= 0) {\n    return(NA_real_)\n  }\n\n  tmp <- (x + 0.5) * log(tmp) - tmp\n  # ser <- 1L\n  x <-  c(x + 1:6)\n  ser <- sum(cof / x) + 1\n\n  if (stp * ser <= 0) {\n    return(NA_real_)\n  }\n\n  return(tmp + log(stp * ser))\n}\n\n\nAnnotated version:\n\n\nShow the code\nGAMMLN <- function(xx) {\n  # Coefficients for the Lanczos approximation; these are pre-computed constants\n  cof <- c(76.18009173, \n           -86.50532033, \n           24.01409822, \n           -1.231739516, \n           0.120858003e-2, \n           -0.536382e-5)\n  \n  # sqrt(2*pi), which is a part of the normalization constant in the Lanczos formula\n  stp <- 2.50662827465\n  \n  # Constant to offset x for the approximation; gamma = 5 -> equal to gamma + 1/2\n  fpf <- 5.5\n  \n  # Adjust the input xx by subtracting 1, given that we calculate it for z + 1\n  x <- xx - 1\n  \n  # Calculate the term (z + gamma + 1/2)\n  tmp <- x + fpf\n  \n  # Check if the adjusted term is non-positive\n  if (tmp <= 0) {\n    return(NA_real_)\n  }\n\n  # Calculate part of the Lanczos formula:\n  # This corresponds to the (z + gamma + 1/2)^(z + 1/2) * e^(-(z + gamma + 1/2)) in the approximation\n  # e is the base of the natural logarithm; since we are calculating the log-gamma,\n  # we are taking the log of e^(-(z+gamma+1/2)), which simplifies to just -(z+gamma+1/2)\n  tmp <- (x + 0.5) * log(tmp) - tmp\n  \n  # Create a sequence of (z+1) to (z+6) for the Lanczos series in the denominator\n  x <-  c(x + 1:6)\n  \n  # Calculate the Lanczos series sum using the coefficients (cof)\n  # and add 1 to it for the c_0 term in the Lanczos formula\n  ser <- sum(cof / x) + 1\n\n  # Check if the final series is non-positive\n  if (stp * ser <= 0) {\n    return(NA_real_)\n  }\n\n  # Return the final computed value of the logarithm of the gamma function\n  # This combines the calculated series with the earlier part and the log of the normalization constant (stp)\n  return(tmp + log(stp * ser))\n}\n\n\nReferences:[6]\nRelevant equations: The gamma function is defined by the integral: \\[\\Gamma(z) = \\int_0^{\\infty} t^{z-1} e^{-t} \\, dt\\]\nTo calculate it numerically, we use an approximation. The best approximation we have is the Lanczos approximation[6], which we use here:\n\\[\\begin{align*}\n\\Gamma(z + 1) &\\approx (z + \\gamma + \\frac{1}{2})^{z+\\frac{1}{2}} e^{-(z+\\gamma+\\frac{1}{2})} \\\\\n& \\quad \\times \\sqrt{2\\pi} \\left[ c_0 + \\frac{c_1}{z + 1} + \\frac{c_2}{z + 2} + \\ldots + \\frac{c_N}{z + N} + \\epsilon \\right] \\\\\n& \\\\\n& with \\quad (z > 0)\n\\end{align*}\\]\nWith parameters \\(\\gamma = 5\\) and \\(N = 6\\).\nAs noted in [6], it is easier to compute the logarithm of the gamma function, which is what this function does. Therefore, the actual equation we use is this:\n\\[\\begin{align*}\n\\ln(\\Gamma(z + 1)) & \\approx \\left( z + \\frac{1}{2} \\right) \\ln\\left( z + \\gamma + \\frac{1}{2} \\right) - \\left( z + \\gamma + \\frac{1}{2} \\right) + \\ln\\left( \\sqrt{2\\pi} \\right) \\\\\n& \\quad + \\ln\\left( c_0 + \\frac{c_1}{z + 1} + \\frac{c_2}{z + 2} + \\ldots + \\frac{c_N}{z + N} \\right)\n\\end{align*}\\]\nSteps:\n\ncof is an array of coefficients(\\(c_{1}, c_{2}, ... , c_{n}\\)) used for the series expansion.\n\n\n\n\n\n\n\nIssue:\n\n\n\nThe coefficients chosen in the Lanczos approximation are not used anymore in the newest implementations of the C code. The newest literature suggests different coefficients (Available in the third edition of Numerical Recipes in C)\n\n\n\nCompute the adjusted input: Adjust the input value xx to x by subtracting one to align with the formulation in the Lanczos approximation, which is \\(\\Gamma(z + 1)\\).\nCheck for non-positive input: If the adjusted input is non-positive, return NA_real_ as the computation cannot proceed with non-positive values (\\(z > 0\\)).\nCreate fpf: this is equivalent to \\(\\gamma + \\frac{1}{2}\\), with \\(\\gamma = 5\\).\nCompute the Lanczos sum: Initialize the variable ser with 1.0 (\\(c_{0}\\)), then add the terms of the Lanczos sum using a for loop. Each term is a coefficient from the cof vector divided by the incremented input x.\nCalculate the final log-gamma value: Combine the logarithm of stp (\\(\\sqrt{2\\pi}\\)) with the sum ser and the main part of the Lanczos approximation involving tmp.\nReturn the result: The function returns the computed value, which is the natural logarithm of the gamma function for the input xx.\n\n\n\n1.25 rtSafe\nDescription: rtSafeis an implementation of a ‘safe’ version of rtNewt. It adds checks to ensure that the method is robust and converges correctly.\n\n\nShow the code\nrtSafe <- function(x1, x2, xacc, mean, povline, A, B, C) {\n  \n  # Evaluate the function at the initial guesses x1 and x2:\n  \n  funcCall1 <- funcD(x1, mean, povline, A, B, C)\n  fl <- funcCall1[[1]]  # Function value at x1 (low)\n\n  funcCall2 <- funcD(x2, mean, povline, A, B, C)\n  fh <- funcCall2[[1]]  # Function value at x2 (high)\n  df <- funcCall2[[2]]  # Derivative value at x2\n\n  # Check if the function values at x1 and x2 bracket a root (have opposite signs)\n  if (fl * fh >= 0) {\n    # If they do not bracket a root, fall back to the Newton-Raphson method (which has larger brackets)\n    res <- rtNewt(mean = mean, povline = povline, A = A, B = B, C = C)\n    return(res)\n  }\n\n  # Assign xl and xh to bracket the root with xl having a function value less than 0\n  if (fl < 0) {\n    xl <- x1\n    xh <- x2\n  } else {\n    xl <- x2\n    xh <- x1\n  }\n\n  # Initialize the safe guess for the root as the midpoint between x1 and x2\n  rtsafe <- 0.5 * (x1 + x2)\n  # Set the full step and fractional step sizes to the interval length\n  dxold <- abs(x2 - x1)\n  dx <- dxold\n\n  # Enter the main iteration loop\n  for (i in seq_len(99)) {\n    # Update the function and derivative at the current guess rtsafe\n    funcCall3 <- funcD(rtsafe, mean, povline, A, B, C)\n    f <- funcCall3[[1]]\n    df <- funcCall3[[2]]\n\n    # Check for convergence by comparing the change in the root with the tolerance\n    if (abs(2 * f) > abs(dxold * df)) {\n      # If not converging, bisect the interval\n      dxold <- dx\n      dx <- 0.5 * (xh - xl)\n      rtsafe <- xl + dx\n      if (xl == rtsafe) return(rtsafe)  # Check for underflow\n    } else {\n      # If converging, use Newton-Raphson step\n      dxold <- dx\n      dx <- f / df\n      temp <- rtsafe\n      rtsafe <- temp - dx\n      if (temp == rtsafe) return(rtsafe)  # Check for underflow\n    }\n\n    # If the size of the Newton-Raphson step is less than the tolerance, return the root\n    if (abs(dx) < xacc) return(rtsafe)\n\n    # Update the function value at the new guess\n    funcCall4 <- funcD(rtsafe, mean, povline, A, B, C)\n    f <- funcCall4[[1]]\n\n    # Update the interval bounds to continue the bisection process\n    if (f < 0) {\n      xl <- rtsafe\n    } else {\n      xh <- rtsafe\n    }\n  }\n  # If the loop finishes without returning, it indicates failure to converge\n  return(NA_real_)\n}\n\n\nSteps:\n\nInput parameters:\n\n\nx1 and x2: initial guesses for the root, defining a bracket within which the root lies.\nxacc: desired accuracy for the root.\nmean, povline, and the parameters of the Lorenz curve.\n\n\nInitial Function Evaluation:\n\nCalculate the function values at x1 and x2.\nIf the function values at these points do not bracket a root (i.e., the function values are not of opposite signs), the function will revert to use rtNewt directly, using larger default bounds (0 and 1).\n\nBracketing the Root:\n\nAssign xl and xh to be the lower and upper bounds of the bracketing interval, respectively.\nEnsure that the lower bound xl has a function value less than zero.\nNote: According to the Intermediate Value Theorem, if a continuous function changes sign over an interval, then there must be at least one root (zero crossing) within that interval. Therefore, bracketing is a way of confirming that within the interval [xl, xh] there is at least one root.\n\nIterative Process:\n\nInitialize the midpoint guess for the root, rtsafe, as halfway between x1 and x2.\nSet up variables dxold and dx to control the iteration step size.\n\nMain Iteration Loop:\n\nFor each iteration, calculate the function value and its derivative at rtsafe.\nUse a combination of bisection and Newton-Raphson updates to adjust rtsafe and home in on the root.\nIf the function value at the new guess rtsafe is negative, update xl; otherwise, update xh.\nCheck for convergence by comparing the change in rtsafe with the tolerance xacc.\nRepeat this process for a maximum of 99 iterations or until the root is found within the desired accuracy.\n\nConvergence Check:\n\nIf the algorithm converges to a root within the desired accuracy, the function returns the value of rtsafe.\nIf the function fails to converge within the set number of iterations, it returns NA_real_ to indicate an unsuccessful search.\n\n\n\n\n1.26 funcD\nDescription: funcD returns two equations needed to calculate \\(H\\) when using \\[L'(H) + \\frac{z}{\\mu} - 1 = 0\\].\n\n\nShow the code\nfuncD <- function(x, mean, povline, A, B, C) {\n  x1 <- 1 - x\n  v1 <- (x^B) * (x1^C)\n  f <- (A * v1 * ((B / x) - (C / x1))) + (povline / mean) - 1\n  df <- A * v1 * (((B / x) - (C / x1))^2 - (B / x^2) - (C / x1^2))\n  return(list(\n    f = f,\n    df = df\n  ))\n}\n\n\nRelevant Equations:\n\nf is equivalent to \\(L'(H) + \\frac{z}{\\mu} - 1 = 0\\)\ndf is the derivative of f.\n\nSee rtNewt for more details.\n\n\n1.27 rtNewt\nDescription: rtNewt uses the Newton-Raphson iteration to find \\(H\\) (the headcount) using: \\[L'(H) + \\frac{z}{\\mu} - 1 = 0\\].\n\n\nShow the code\nrtNewt <- function(mean, povline, A, B, C) {\n  # Initial bounds of the search interval\n  x1 <- 0L\n  x2 <- 1L\n  # Accuracy tolerance for the solution\n  xacc <- 1e-4\n  # Initial guess for the root, halfway between x1 and x2\n  rtnewt <- 0.5 * (x1 + x2)\n\n  # Perform up to 19 iterations to find the root\n  for (i in seq_len(19)) {\n    # Current guess for the proportion of the population\n    x <- rtnewt\n    # Part of the Lorenz curve derivative: x^B * (1 - x)^C\n    v1 <- (x^B) * ((1 - x)^C)\n    # The function whose root we're finding; it's the difference between the\n    # Lorenz curve's derivative at x and the normalized poverty line\n    f <- A * v1 * ((B / x) - (C / (1 - x))) + (povline / mean) - 1\n    # Derivative of f with respect to x\n    df <- A * v1 * (((B / x) - (C / (1 - x)))^2 - (B / x^2) - (C / (1 - x)^2))\n    # Newton-Raphson step size\n    dx <- f / df\n    # Update the current guess for the root\n    rtnewt <- rtnewt - dx\n\n    # Check if the new guess is outside the initial interval\n    if ((x1 - rtnewt) * (rtnewt - x2) < 0) {\n      # Reset rtnewt to the midpoint of the interval closer to the bounds\n      rtnewt <- if (rtnewt < x1) { 0.5 * (x2 - x) } else { 0.5 * (x - x1) }\n    } else {\n      # If the change in the root estimate is smaller than the tolerance, return it\n      if (abs(dx) < xacc) {\n        return(rtnewt)\n      }\n    }\n  }\n  # If no convergence, return NA to indicate failure\n  return(NA_real_)\n}\n\n\nRelevant equations:\nThe first derivative of the Lorenz Beta curve evaluated at \\(H\\) is equal to:\n$$\n\\[\\begin{aligned}\nL'(H) = 1 - \\frac{z}{\\mu} \\\\\n\\theta H^\\gamma (1-H)^\\delta [\\frac{\\gamma}{H} - \\frac{\\delta}{1-H}] = 1 - \\frac{z}{\\mu}\n\n\\end{aligned}\\]\n$$\nThe Newton-Raphson iteration is used to find the root of an equation. In our case, this means finding when \\(L'(H) = 0\\) or:\n\\[\n\\theta H^\\gamma (1-H)^\\delta [\\frac{\\gamma}{H} - \\frac{\\delta}{1-H}] + \\frac{z}{\\mu} - 1 = 0\n\\]\nSteps:\n\nInitialize the algorithm:\n\nx1 and x2 are the initial boundaries of the search interval\nxacc is the accuracy tolerance for the solution\nrtnewt is the initial guess for the root, taken as the midpoint of the interval [x1, x2]\n\nBegin the Iterative process:\n\nEach iteration consists of:\n\nv1 calculates a part of the function we need to solve for \\(f(x) = L'(H)\\), \\(x^B (1-x)^C = H^\\gamma (1-H)^\\delta\\).\nf sets up the function \\(f(x) = L'(H)\\) as defined above.\ndf sets up the derivative \\(f'(x) = L''(H)\\).\n\n\nUpdate the Guess for the Root\n\ndx calculates the Newton-Raphson step size (dx = f/df = \\(\\frac{f(x_{old})}{f'(x_{old})}\\))\nrtnewt updates the current guess by subtracting dx from it. This step is based on the Newton-Raphson update rule:\n\n\\[x_{new} = x_{old} - \\frac{f(x_{old})}{f'(x_{old})}\\]\nCheck for interval boundaries and convergence: after each iteration, the algorithm checks whether the new guess rtnewt is within the initial interval [x1, x2]. If it is not, the interval is adjusted. If the guess is within the desired accuracy, the function returns the root rtnewt.\n\n…"
  },
  {
    "objectID": "wbpip_gd_doc.html#references",
    "href": "wbpip_gd_doc.html#references",
    "title": "Group Data Documentation (wbpip)",
    "section": "2 References",
    "text": "2 References\n\nVillasenor, J., B. C. Arnold. 1989. “Elliptical Lorenz curves”. Journal of Econometrics 40 (2): 327-338.\nKrause, M. 2013. “Corrigendum to Elliptical Lorenz curves”. Journal of Econometrics 174 (1): 44.\nDatt, G. 1998. “Computational Tools For Poverty Measurement And Analysis”. FCND Discussion Paper 50. World Bank, Washington, DC.\nRohde, N. (2008). “Lorenz Curves and Generalised Entropy Inequality Measures”. In: Chotikapanich, D. (eds) Modeling Income Distributions and Lorenz Curves. Economic Studies in Equality, Social Exclusion and Well-Being, vol 5. Springer, New York, NY.\nKakwani, N. 1980. “On a Class of Poverty Measures”. Econometrica 48 (2): 437-46.\nPress, W. H. et al. 1992. “Gamma Function, Beta Function, Factorials, Binomial Coefficients, Section 6.1, page 213 in Numerical recipes in C: the art of scientific computing (2nd edition, Cambridge Univeristy Press."
  },
  {
    "objectID": "wbpip_gd_doc.html#appendix",
    "href": "wbpip_gd_doc.html#appendix",
    "title": "Group Data Documentation (wbpip)",
    "section": "3 Appendix",
    "text": "3 Appendix\nFind function using the following list:\n\nSection 1.1: gd_compute_pip_stats\nSection 1.2: gd_select_lorenz\ngd_compute_pip_stats_lq\ngd_compute_pip_stats_lb\ncreate_functional_form_lq\nderive_lq\ngd_estimate_lq\ncheck_curve_validity_lq\ngd_compute_dist_stats_lq"
  }
]